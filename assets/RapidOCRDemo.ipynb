{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RapidOCRDemo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
     {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RapidAI/RapidOCR/blob/main/RapidOCRDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## RapidOCR Python Demo\n",
        "\n"
      ],
      "metadata": {
        "id": "8H17bBI3N-vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set up"
      ],
      "metadata": {
        "id": "8rzOal8MOSxQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igjCwq2FN9Ki",
        "outputId": "0e72645c-cd6f-44fa-a670-e397826b20e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RapidOCR'...\n",
            "remote: Enumerating objects: 3447, done.\u001b[K\n",
            "remote: Counting objects: 100% (397/397), done.\u001b[K\n",
            "remote: Compressing objects: 100% (299/299), done.\u001b[K\n",
            "remote: Total 3447 (delta 191), reused 228 (delta 77), pack-reused 3050\u001b[K\n",
            "Receiving objects: 100% (3447/3447), 13.93 MiB | 23.69 MiB/s, done.\n",
            "Resolving deltas: 100% (1563/1563), done.\n",
            "/content/RapidOCR/python/RapidOCR/python\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/RapidAI/RapidOCR.git\n",
        "%cd RapidOCR/python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -i https://pypi.douban.com/simple/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQa6hnzBSBkk",
        "outputId": "21828751-246d-4e39-fa16-9b1f0ffa4b48"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.douban.com/simple/\n",
            "Requirement already satisfied: pyclipper==1.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: Shapely==1.7.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.7.1)\n",
            "Requirement already satisfied: onnxruntime==1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.7.0)\n",
            "Requirement already satisfied: opencv_python==4.5.1.48 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (4.5.1.48)\n",
            "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: numpy==1.19.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.19.2)\n",
            "Requirement already satisfied: Pillow==8.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (8.3.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.7.0->-r requirements.txt (line 3)) (3.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \"https://docs.google.com/uc?export=download&id=1MurIeU78qIGN8Jb2dK2_mnmEsEHH0Jct\" -O models.zip\n",
        "!rm -r models/\n",
        "!unzip models.zip && rm models.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmJ9K93SOtB0",
        "outputId": "e4b1a60d-25fd-46a6-b56d-87d1543ce503"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-18 02:57:05--  https://docs.google.com/uc?export=download&id=1MurIeU78qIGN8Jb2dK2_mnmEsEHH0Jct\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.164.142, 2607:f8b0:4004:814::200e\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.164.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-3s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0rm8hfqhdh2brc42fbgdpmndj0h54gss/1639796175000/10158993189489619361/*/1MurIeU78qIGN8Jb2dK2_mnmEsEHH0Jct?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-12-18 02:57:11--  https://doc-00-3s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0rm8hfqhdh2brc42fbgdpmndj0h54gss/1639796175000/10158993189489619361/*/1MurIeU78qIGN8Jb2dK2_mnmEsEHH0Jct?e=download\n",
            "Resolving doc-00-3s-docs.googleusercontent.com (doc-00-3s-docs.googleusercontent.com)... 172.217.2.97, 2607:f8b0:4004:80a::2001\n",
            "Connecting to doc-00-3s-docs.googleusercontent.com (doc-00-3s-docs.googleusercontent.com)|172.217.2.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18799754 (18M) [application/x-zip-compressed]\n",
            "Saving to: ‘models.zip’\n",
            "\n",
            "models.zip          100%[===================>]  17.93M  28.6MB/s    in 0.6s    \n",
            "\n",
            "2021-12-18 02:57:13 (28.6 MB/s) - ‘models.zip’ saved [18799754/18799754]\n",
            "\n",
            "Archive:  models.zip\n",
            "   creating: models/\n",
            "  inflating: models/ch_PP-OCRv2_det_infer.onnx  \n",
            "  inflating: models/ch_ppocr_mobile_v2.0_cls_infer.onnx  \n",
            "  inflating: models/ch_ppocr_mobile_v2.0_rec_infer.onnx  \n",
            "  inflating: models/msyh.ttc         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run as shell script"
      ],
      "metadata": {
        "id": "xG5YEcJ_el8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash rapidOCR.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCAzq3GMRp8k",
        "outputId": "c23b3729-1527-4f7b-99da-f7fefd1a42c1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"rapidOCR.py\", line 295, in <module>\n",
            "    keys_path=args.keys_path)\n",
            "  File \"rapidOCR.py\", line 154, in __init__\n",
            "    self.text_detector = TextDetector(det_model_path)\n",
            "  File \"/content/RapidOCR/python/RapidOCR/python/ch_ppocr_mobile_v2_det/text_detect.py\", line 62, in __init__\n",
            "    self.session = onnxruntime.InferenceSession(det_model_path, sess_opt)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 280, in __init__\n",
            "    self._create_inference_session(providers, provider_options)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 307, in _create_inference_session\n",
            "    sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)\n",
            "onnxruntime.capi.onnxruntime_pybind11_state.NoSuchFile: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from models/ch_ppocr_mobile_v2.0_det_infer.onnx failed:Load model models/ch_ppocr_mobile_v2.0_det_infer.onnx failed. File doesn't exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run as code"
      ],
      "metadata": {
        "id": "PDlCLO_CewSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "from ch_ppocr_mobile_v2_cls import TextClassifier\n",
        "from ch_ppocr_mobile_v2_det import TextDetector\n",
        "from ch_ppocr_mobile_v2_rec import TextRecognizer"
      ],
      "metadata": {
        "id": "bbHGS0emSNTz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_ocr_box_txt(image, boxes, txts,\n",
        "                     scores=None, text_score=0.5,\n",
        "                     font_path=\"./models/msyh.ttc\"):\n",
        "    h, w = image.height, image.width\n",
        "    img_left = image.copy()\n",
        "    img_right = Image.new('RGB', (w, h), (255, 255, 255))\n",
        "\n",
        "    random.seed(0)\n",
        "    draw_left = ImageDraw.Draw(img_left)\n",
        "    draw_right = ImageDraw.Draw(img_right)\n",
        "    for idx, (box, txt) in enumerate(zip(boxes, txts)):\n",
        "        if scores is not None and scores[idx] < text_score:\n",
        "            continue\n",
        "\n",
        "        color = (random.randint(0, 255),\n",
        "                 random.randint(0, 255),\n",
        "                 random.randint(0, 255))\n",
        "        draw_left.polygon(box, fill=color)\n",
        "        draw_right.polygon([box[0][0], box[0][1],\n",
        "                            box[1][0], box[1][1],\n",
        "                            box[2][0], box[2][1],\n",
        "                            box[3][0], box[3][1]],\n",
        "                           outline=color)\n",
        "\n",
        "        box_height = math.sqrt((box[0][0] - box[3][0])**2\n",
        "                               + (box[0][1] - box[3][1])**2)\n",
        "\n",
        "        box_width = math.sqrt((box[0][0] - box[1][0])**2\n",
        "                              + (box[0][1] - box[1][1])**2)\n",
        "\n",
        "        if box_height > 2 * box_width:\n",
        "            font_size = max(int(box_width * 0.9), 10)\n",
        "            font = ImageFont.truetype(font_path, font_size,\n",
        "                                      encoding=\"utf-8\")\n",
        "            cur_y = box[0][1]\n",
        "            for c in txt:\n",
        "                char_size = font.getsize(c)\n",
        "                draw_right.text((box[0][0] + 3, cur_y), c,\n",
        "                                fill=(0, 0, 0), font=font)\n",
        "                cur_y += char_size[1]\n",
        "        else:\n",
        "            font_size = max(int(box_height * 0.8), 10)\n",
        "            font = ImageFont.truetype(font_path, font_size,\n",
        "                                      encoding=\"utf-8\")\n",
        "            draw_right.text([box[0][0], box[0][1]], txt,\n",
        "                            fill=(0, 0, 0), font=font)\n",
        "\n",
        "    img_left = Image.blend(image, img_left, 0.5)\n",
        "    img_show = Image.new('RGB', (w * 2, h), (255, 255, 255))\n",
        "    img_show.paste(img_left, (0, 0, w, h))\n",
        "    img_show.paste(img_right, (w, 0, w * 2, h))\n",
        "    return np.array(img_show)\n",
        "\n",
        "\n",
        "def visualize(image_path, boxes, rec_res):\n",
        "    image = Image.open(image_path)\n",
        "    txts = [rec_res[i][0] for i in range(len(rec_res))]\n",
        "    scores = [rec_res[i][1] for i in range(len(rec_res))]\n",
        "\n",
        "    draw_img = draw_ocr_box_txt(image, boxes,\n",
        "                                txts, scores,\n",
        "                                text_score=0.5)\n",
        "\n",
        "    draw_img_save = Path(\"./inference_results/\")\n",
        "    if not draw_img_save.exists():\n",
        "        draw_img_save.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    image_save = str(draw_img_save / f'infer_{Path(image_path).name}')\n",
        "    cv2.imwrite(image_save, draw_img[:, :, ::-1])\n",
        "    print(f'The infer result has saved in {image_save}')\n",
        "\n",
        "\n",
        "class TextSystem(object):\n",
        "    def __init__(self, det_model_path,\n",
        "                    rec_model_path,\n",
        "                    use_angle_cls=False,\n",
        "                    cls_model_path=None,\n",
        "                    keys_path=None):\n",
        "        super(TextSystem).__init__()\n",
        "        self.text_detector = TextDetector(det_model_path)\n",
        "        self.text_recognizer = TextRecognizer(rec_model_path, keys_path)\n",
        "        self.use_angle_cls = use_angle_cls\n",
        "        if self.use_angle_cls:\n",
        "            self.text_classifier = TextClassifier(cls_model_path)\n",
        "        self.text_score = 0.5\n",
        "\n",
        "    def get_rotate_crop_image(self, img, points):\n",
        "        '''\n",
        "        img_height, img_width = img.shape[0:2]\n",
        "        left = int(np.min(points[:, 0]))\n",
        "        right = int(np.max(points[:, 0]))\n",
        "        top = int(np.min(points[:, 1]))\n",
        "        bottom = int(np.max(points[:, 1]))\n",
        "        img_crop = img[top:bottom, left:right, :].copy()\n",
        "        points[:, 0] = points[:, 0] - left\n",
        "        points[:, 1] = points[:, 1] - top\n",
        "        '''\n",
        "        img_crop_width = int(\n",
        "            max(\n",
        "                np.linalg.norm(points[0] - points[1]),\n",
        "                np.linalg.norm(points[2] - points[3])))\n",
        "        img_crop_height = int(\n",
        "            max(\n",
        "                np.linalg.norm(points[0] - points[3]),\n",
        "                np.linalg.norm(points[1] - points[2])))\n",
        "        pts_std = np.float32([[0, 0], [img_crop_width, 0],\n",
        "                                [img_crop_width, img_crop_height],\n",
        "                                [0, img_crop_height]])\n",
        "        M = cv2.getPerspectiveTransform(points, pts_std)\n",
        "        dst_img = cv2.warpPerspective(\n",
        "            img,\n",
        "            M, (img_crop_width, img_crop_height),\n",
        "            borderMode=cv2.BORDER_REPLICATE,\n",
        "            flags=cv2.INTER_CUBIC)\n",
        "        dst_img_height, dst_img_width = dst_img.shape[0:2]\n",
        "        if dst_img_height * 1.0 / dst_img_width >= 1.5:\n",
        "            dst_img = np.rot90(dst_img)\n",
        "        return dst_img\n",
        "\n",
        "    @staticmethod\n",
        "    def sorted_boxes(dt_boxes):\n",
        "        \"\"\"\n",
        "        Sort text boxes in order from top to bottom, left to right\n",
        "        args:\n",
        "            dt_boxes(array):detected text boxes with shape [4, 2]\n",
        "        return:\n",
        "            sorted boxes(array) with shape [4, 2]\n",
        "        \"\"\"\n",
        "        num_boxes = dt_boxes.shape[0]\n",
        "        sorted_boxes = sorted(dt_boxes, key=lambda x: (x[0][1], x[0][0]))\n",
        "        _boxes = list(sorted_boxes)\n",
        "\n",
        "        for i in range(num_boxes - 1):\n",
        "            if abs(_boxes[i + 1][0][1] - _boxes[i][0][1]) < 10 and \\\n",
        "                    (_boxes[i + 1][0][0] < _boxes[i][0][0]):\n",
        "                tmp = _boxes[i]\n",
        "                _boxes[i] = _boxes[i + 1]\n",
        "                _boxes[i + 1] = tmp\n",
        "        return _boxes\n",
        "\n",
        "    @staticmethod\n",
        "    def load_image(image_path):\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"error in loading image:{image_path}\")\n",
        "        return img\n",
        "\n",
        "    def __call__(self, image_path):\n",
        "        img = self.load_image(image_path)\n",
        "        dt_boxes, elapse = self.text_detector(img)\n",
        "        print(\"dt_boxes num : {}, elapse : {}\".format(\n",
        "            len(dt_boxes), elapse))\n",
        "        if dt_boxes is None or len(dt_boxes) < 1:\n",
        "            return None, None\n",
        "        dt_boxes = self.sorted_boxes(dt_boxes)\n",
        "\n",
        "        img_crop_list = []\n",
        "        for bno in range(len(dt_boxes)):\n",
        "            tmp_box = copy.deepcopy(dt_boxes[bno])\n",
        "            img_crop = self.get_rotate_crop_image(img, tmp_box)\n",
        "            img_crop_list.append(img_crop)\n",
        "\n",
        "        if self.use_angle_cls:\n",
        "            img_crop_list, angle_list, elapse = self.text_classifier(\n",
        "                img_crop_list)\n",
        "            print(\"cls num  : {}, elapse : {}\".format(\n",
        "                len(img_crop_list), elapse))\n",
        "\n",
        "        rec_res, elapse = self.text_recognizer(img_crop_list)\n",
        "        print(\"rec_res num  : {}, elapse : {}\".format(\n",
        "            len(rec_res), elapse))\n",
        "\n",
        "        filter_boxes, filter_rec_res = [], []\n",
        "        for box, rec_reuslt in zip(dt_boxes, rec_res):\n",
        "            text, score = rec_reuslt\n",
        "            if score >= self.text_score:\n",
        "                filter_boxes.append(box)\n",
        "                filter_rec_res.append(rec_reuslt)\n",
        "        return filter_boxes, filter_rec_res"
      ],
      "metadata": {
        "id": "JUsafRjKWFRY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "det_model_path = \"models/ch_PP-OCRv2_det_infer.onnx\"\n",
        "rec_model_path = \"models/ch_ppocr_mobile_v2.0_rec_infer.onnx\"\n",
        "cls_model_path = \"models/ch_ppocr_mobile_v2.0_cls_infer.onnx\"\n",
        "\n",
        "keys_path = \"ch_ppocr_mobile_v2_rec/ppocr_keys_v1.txt\"\n",
        "\n",
        "text_sys = TextSystem(det_model_path, \n",
        "            rec_model_path, \n",
        "            use_angle_cls=True, \n",
        "            cls_model_path=cls_model_path, \n",
        "            keys_path=keys_path)"
      ],
      "metadata": {
        "id": "OthLjvHiWlRq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/RapidOCR/images/1.jpg'\n",
        "dt_boxes, rec_res = text_sys(img_path)\n",
        "print(rec_res)\n",
        "visualize(img_path, dt_boxes, rec_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1pvq6etbfju",
        "outputId": "73154a63-75c4-4782-b717-38a97fc074ce"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dt_boxes num : 18, elapse : 0.3534584045410156\n",
            "cls num  : 18, elapse : 0.03909873962402344\n",
            "rec_res num  : 18, elapse : 0.14548611640930176\n",
            "The infer result has saved in inference_results/infer_1.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_Zy_vIdPYIZw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
